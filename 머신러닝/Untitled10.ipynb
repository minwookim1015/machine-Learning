{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71e9a6b2-fecf-4a90-98d0-65ae573059da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wine=pd.read_csv('https://bit.ly/wine_csv_data')\n",
    "\n",
    "data=wine[['alcohol','sugar','pH']].to_numpy()\n",
    "target=wine['class'].to_numpy()\n",
    "\n",
    "train_input,test_input,train_target,test_target=train_test_split(data,target,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34d18496-07b9-4bde-8719-52f5455c662f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9979796012752471 0.8932079662397274\n",
      "[0.23853083 0.49468716 0.26678201]\n",
      "0.8976332499518953\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier #랜덤 포레스트 알고리즘\n",
    "\n",
    "rf=RandomForestClassifier(n_jobs=-1,random_state=42)\n",
    "scores=cross_validate(rf,train_input,train_target,return_train_score=True,n_jobs=-1)\n",
    "#return_train_score=True 을 하게 되면 기본적으로 cross_validate에서 나오는 값은 검증세트에 대한 스코어 값이지만 훈련세트의 스코어 값도 반환하여 둘이 비교할 수 있다\n",
    "print(np.mean(scores['train_score']),np.mean(scores['test_score']))\n",
    "\n",
    "rf.fit(train_input,train_target)\n",
    "print(rf.feature_importances_)#특성트리의 중요도\n",
    "#부트스트랩 샘플을 만들때 남는 샘플을 oob라고 한다. 이것들을 활용해서 마치 검증세트로서 활용 할 수 있음\n",
    "rf=RandomForestClassifier(oob_score=True,n_jobs=-1,random_state=42)\n",
    "\n",
    "rf.fit(train_input,train_target)\n",
    "print(rf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0837c527-dd84-4249-a25a-efe185bc4f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9979796012752471 0.8845504183016214\n",
      "[0.20401879 0.52110469 0.27487653]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier #엑스트라 트리 알고리즘\n",
    "#부트스트랩 샘플을 사용하지 않고 노드를 분할 할때 A B C의 특성을 램덤하게 분할하여 불순도가 가장 좋은 샘플을 사용하여 과대적합을 해소\n",
    "#램덤하게 분할하기 때문에 속도가 굉장히 빠르지만 트리가 많이 생성되면 될수록 성능이 좋아지기 때문에 많은 트리가 필요하다 \n",
    "et=ExtraTreesClassifier(n_jobs=-1,random_state=42)\n",
    "scores=cross_validate(et,train_input,train_target,return_train_score=True,n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']),np.mean(scores['test_score']))\n",
    "\n",
    "et.fit(train_input,train_target)\n",
    "print(et.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99be41f0-74b6-49bb-9f87-82d67451a857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8844523565957292 0.868576108684386\n",
      "0.9454013426589803 0.8724276301177166\n",
      "[0.16788068 0.68431409 0.14780523]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier #그레디언트 부스팅\n",
    "#경사 하강법 과 굉장히 유사한 방법 분류 일때-> 로지스틱 손실함수  회귀 일때->평균 제곱 오차\n",
    "#손실함수의 값들은 결국 실수 값이 나오는데 실수 값을 낮아지도록 트리를 추가하는 방법 즉 잔여 오차에 대하여 학습하는 트리를 계속하여 추가한다. \n",
    "#회귀 트리를 추가 max_depth=3으로 지정-> 깊이가 낮은 트리(과대적합 가능성 적음) but 성능이 좋지 않음 이를 트리를 추가해 성능을 올림\n",
    "# remind! 손실함수를 정의하고 손실함수의 최저값을 찾는 방법-> 가중치 변경하면서(경사하강법)\n",
    "\n",
    "gb=GradientBoostingClassifier(random_state=42)\n",
    "scores=cross_validate(gb,train_input,train_target,return_train_score=True,n_jobs=-1)\n",
    "print(np.mean(scores['train_score']),np.mean(scores['test_score']))\n",
    "\n",
    "gb=GradientBoostingClassifier(n_estimators=500,learning_rate=0.2,random_state=42)\n",
    "#손실함수의 더 낮은 부분으로 이동 경사각도 변경\n",
    "scores=cross_validate(gb,train_input,train_target,return_train_score=True,n_jobs=-1)\n",
    "print(np.mean(scores['train_score']),np.mean(scores['test_score']))\n",
    "\n",
    "gb.fit(train_input,train_target)\n",
    "print(gb.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a32a0bef-c964-43d2-8993-a411cf80ae36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\XAI\\Lib\\site-packages\\sklearn\\experimental\\enable_hist_gradient_boosting.py:15: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9310662092475901 0.8801221588805804\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting #히스토그램 기반 그레디언트 부스팅\n",
    "#특성의 범위가 제한되어 있기 때문에 속도가 빠르고 과대적합을 막고 성능이 좋게 된다.\n",
    "#255개의 구간으로 나누고 나머지 한개의 구간은 누락된 값에 대해서 할당을 함 \n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb=HistGradientBoostingClassifier(random_state=42)\n",
    "scores=cross_validate(hgb,train_input,train_target,return_train_score=True,n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']),np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f1ddbe5-062b-4844-b9b3-649942325135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\XAI\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\user\\anaconda3\\envs\\XAI\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09270733 0.23777179 0.08735809]\n",
      "[0.05484615 0.20123077 0.04538462]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8776923076923077"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance #permutation importance 치환 중요도\n",
    "#특성 열과 샘플 행에서 첫번째 특성을 섞음 \n",
    "#특성의 중요도를 알 수 있음 예를 들어 첫번째 특성을 섞었을때 성능이 80% 두번째 특성을 섞었을 때 성능이 70%이면 \n",
    "#두번째 성능을 섞었을 때 성능이 더 안좋아졌으므로 두번째 특성이 더욱더 중요한 특성임을 알 수 있음\n",
    "hgb.fit(train_input,train_target)\n",
    "result=permutation_importance(hgb,train_input,train_target,n_repeats=10,random_state=42,n_jobs=-1)\n",
    "#n_repeats의 기본값은 5\n",
    "\n",
    "print(result.importances_mean)\n",
    "\n",
    "result=permutation_importance(hgb,test_input,test_target,n_repeats=10,random_state=42,n_jobs=-1)\n",
    "\n",
    "print(result.importances_mean)\n",
    "hgb.score(test_input,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62611a56-c31a-4ce0-94b7-8986bbb3f7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9559361441487976 0.8782005626712076\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier #XGBoost 알고리즘\n",
    "\n",
    "xgb=XGBClassifier(tree_method='hist',random_state=42)\n",
    "#tree_method='hist'로 하면 위의 히스토그램 기반 그레디언트 부스팅 알고리즘으로 사용가능\n",
    "\n",
    "scores=cross_validate(xgb,train_input,train_target,return_train_score=True,n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']),np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e88aa0b-626a-418d-a121-c69e857b8e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9559361441487976 0.8782005626712076\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgb=LGBMClassifier(random_state=42)\n",
    "scores=cross_validate(xgb,train_input,train_target,return_train_score=True,n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']),np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a73f58-f8f5-4e53-abf8-60714b931b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bb7864-c27d-47ea-9119-a3bb09ba8e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a6bdeb-1ad9-472c-98ce-7e3bf134f46b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade1f353-0930-4532-a3a0-c0f3367ddbae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e89d0f-f165-47ba-8737-d4ced2017f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d00e26-d374-4bd2-be1a-644a025ab476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ea4fd9-3484-4c12-b79f-9a15ee685016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0094cf-1bdb-433c-a32b-a3cbdba31883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6df6698-1822-439a-9fe6-d6e8cc1ade03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52700642-f12c-4954-a140-112e5be6c75f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c1cfc4-e1be-44b0-bdc9-9f344880af33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3608abe7-4dd7-4e42-be3c-7aa5407cf212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KER",
   "language": "python",
   "name": "xai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
